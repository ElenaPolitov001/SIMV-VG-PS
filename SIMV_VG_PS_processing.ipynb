{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./University_Debrecen_logo.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the recordings containing SIMV-VG-PS ventilation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Python version: {sys.version}')\n",
    "print(f'pandas version: {pd.__version__}')\n",
    "print(f'matplotlib version: {mpl.__version__}')\n",
    "print(f'numPy version: {np.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. List and set the working directory and the directory to write out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic of the Notebook which will also be the name of the subfolder containing results\n",
    "TOPIC = 'SIMV_VG_PS'\n",
    "\n",
    "# Directory containing clinical and blood gas data\n",
    "DIR_READ_CLIN = os.path.join(os.sep, 'Users', 'guszti', 'ventilation_draeger_debrecen')\n",
    "\n",
    "# Folder on external drive to read the ventilation data from\n",
    "DIR_READ_VENT =  os.path.join(os.sep, 'Volumes', 'Guszti', 'draeger_debrecen',)\n",
    "\n",
    "# Folder to write statistics and reports on the group\n",
    "DIR_WRITE = os.path.join(os.sep, 'Users', 'guszti', 'ventilation_draeger_debrecen', 'Analyses', TOPIC)\n",
    "os.makedirs(DIR_WRITE, exist_ok = True)\n",
    "\n",
    "# Folder on external drive to export graphs and data about individual recordings\n",
    "DATA_DUMP = os.path.join(os.sep, 'Volumes', 'Guszti', 'data_dump', 'draeger_debrecen', TOPIC)\n",
    "os.makedirs(DATA_DUMP, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_READ_CLIN, DIR_READ_VENT, DIR_WRITE, DATA_DUMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import processed clinical details\n",
    "\n",
    "This recording list is produced by the `Clinical_details_processing_debrecen.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details_recordings = pd.read_csv(os.path.join(DIR_READ_CLIN, 'clinical_details_recordings.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clinical_details_recordings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details_patients = pd.read_csv(os.path.join(DIR_READ_CLIN, 'clinical_details_patients.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a list of patients\n",
    "patients = list(clinical_details_patients['Patient'])\n",
    "# Limit the study for the first 20 patients\n",
    "patients = [patient for patient in patients if int(patient[-2:]) <= 20]\n",
    "print(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Import ventilator modes\n",
    "\n",
    "For some recordings of _LVD002_, the ventilator modes (slowText) file is empty. For now I am assuming that they were all SIMV-VG with PS. This needs to be verified later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vent_modes = defaultdict(dict)\n",
    "\n",
    "for patient in patients:\n",
    "    \n",
    "    # Create nested dictionary for each recording\n",
    "    vent_modes_files = [fle for fle in os.listdir(os.path.join(DIR_READ_VENT, patient)) if '_slow_Text' in fle]\n",
    "\n",
    "    for fle in vent_modes_files:\n",
    "        \n",
    "        try: # Some of the slow Text files are empty\n",
    "        \n",
    "            path = os.path.join(DIR_READ_VENT, patient, fle,)\n",
    "            # Use the specific part of the filename as a unique key for the internal dictionary\n",
    "            tag = fle[11:32]\n",
    "            # Import data, parse the 'Date' and 'Time' columns as datetime and combine them \n",
    "            vent_modes[patient][tag] = pd.read_csv(path, parse_dates = [['Date', 'Time']])\n",
    "            # Set the combined 'Date_Time' column as row index\n",
    "            vent_modes[patient][tag] = vent_modes[patient][tag].set_index('Date_Time')\n",
    "            # Drop irrelevant column\n",
    "            vent_modes[patient][tag].drop('Rel.Time [s]', axis = 1, inplace = True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(patient, tag, e)\n",
    "            vent_modes[patient][tag] = DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD006']['2021-11-30_142736.417']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Import ventilator settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_finder(recording, tag):\n",
    "    # There are sometime hidden files on the hard drive starting with '.' \n",
    "    # this step is necessary to ignore them\n",
    "    flist = sorted(file for file in os.listdir(os.path.join(DIR_READ_VENT, patient)) if not file.startswith('.'))\n",
    "    \n",
    "    #Takes a list of filenames and returns those ones that which contain 'tag'\n",
    "    return [os.path.join(DIR_READ_VENT, patient, fname) for fname in flist if tag in fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path):\n",
    "    # This is escaping characters with encoding errors with blackslashes that pd.csv can subsequently handle\n",
    "    with open(path, encoding='utf8' , errors = 'backslashreplace') as input_fd:\n",
    "        data = pd.read_csv(input_fd, keep_date_col = 'True', parse_dates = [['Date', 'Time']])\n",
    "    data.index = data['Date_Time']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(patient, tag):\n",
    "    data = {}\n",
    "    paths = file_finder(patient, tag)\n",
    "    for path in paths:\n",
    "        data['_'.join(path.split('_')[-4:-2])] = data_loader(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_renamer(col_name):\n",
    "\n",
    "    # `VTi` is not correctly labelled, it is actually the target (leak-compensated) expired tidal volume\n",
    "    old_names = ['FiO2', 'VTi', 'Slope', 'Ti', 'Te', 'RR', \n",
    "                 'Pinsp', 'PEEP', 'Pmax', 'Flow trigger', 'ΔPsupp', 'Timax',\n",
    "                 'MAPhf', 'VThf', 'Ampl hf', 'Ampl hf max', 'fhf', 'VG']\n",
    "    new_names = ['FiO2_set [%]', 'VT_set [mL]', 'Slope_set [s]', 'Ti_set [s]', 'Te_set [s]', 'RR_set [1/min]', \n",
    "                 'PIP_set [mbar]', 'PEEP_set [mbar]', 'Pmax_set [mbar]', 'Flow_trigger_set [L/min]', 'PS_set [mbar]', 'Timax_set [s]', \n",
    "                 'MAPhf_set [mbar]', 'VThf_set [mL]', 'Amplhf_set [mbar]', 'Amplhfmax_set [mbar]', 'fhf_set [Hz]', 'VG']\n",
    "    rename_dict = dict(zip(old_names, new_names))\n",
    "        \n",
    "    return rename_dict[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def settings_cleaner(dct):\n",
    "    settings_to_keep = ['FiO2', 'VTi', 'VT', 'Slope', 'Ti', 'Te', 'RR', 'Pinsp', 'PEEP', 'Pmax', \n",
    "        'Flow trigger', 'ΔPsupp','Timax','MAPhf', 'VThf', 'Ampl hf', 'Ampl hf max', 'fhf', ]\n",
    "    \n",
    "    for part in dct:\n",
    "        dframe = dct[part]\n",
    "        # This is required as VTi is given both in mL and in L and keeping both would \n",
    "        # create duplicate columns during unstacking leading to an error message\n",
    "        dframe = dframe[dframe['Unit'] != 'L'] \n",
    "        dframe = dframe[dframe['Id'].isin(settings_to_keep)] \n",
    "        \n",
    "        # Create a new DataFrame with info if the VG was on or not\n",
    "        VG_dframe = pd.DataFrame(index = dframe.index.copy())\n",
    "        VG_dframe['VG'] = np.nan \n",
    "        if 'VTi' in dframe['Id'].unique() and 'Pinsp' in dframe['Id'].unique(): \n",
    "            VG_dframe['VG'][dframe['Id'] == 'VTi'] = 'on' # VG is on\n",
    "            VG_dframe['VG'][dframe['Id'] == 'Pinsp'] = 'off' # VG is off\n",
    "        \n",
    "        elif 'VTi' in dframe['Id'].unique() and 'Pinsp' not in dframe['Id'].unique():\n",
    "            VG_dframe['VG'] = 'on' # VG is on\n",
    "        \n",
    "        elif 'VTi' not in dframe['Id'].unique() and 'Pinsp' in dframe['Id'].unique():\n",
    "            VG_dframe['VG'] = 'off' # VG is off\n",
    "        \n",
    "        VG_dframe['VG'] = VG_dframe['VG'].astype('category')\n",
    "        dframe = dframe.pivot('Date_Time', 'Id', 'Value New')\n",
    "        dframe = pd.merge(dframe, VG_dframe, how = 'outer', left_index = True, right_index = True)\n",
    "        dframe = dframe.fillna(method = 'ffill')\n",
    "        # Rows with duplicated indices need to be removed as otherwise DataFrame cannot be merged with\n",
    "        # slow_measurements. All these rows contain duplicated data anyway.\n",
    "        dframe = dframe[~dframe.index.duplicated(keep='last')]\n",
    "        dframe.rename(col_renamer, axis = 1, inplace = True)\n",
    "        # Remove the microseconds from the time stamp\n",
    "        dframe.index = dframe.index.values.astype('datetime64[s]')\n",
    "        \n",
    "        dct[part] = dframe\n",
    "    \n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vent_settings = {}\n",
    "for patient in patients:\n",
    "    vent_settings[patient] = process_files(patient, 'slow_Setting')\n",
    "    vent_settings[patient] = settings_cleaner(vent_settings[patient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which ventilator settings are present in any recording\n",
    "parameter_present_in_any = set()\n",
    "for patient in vent_settings:\n",
    "    for recording in vent_settings[patient]:\n",
    "        parameter_present_in_any.update(vent_settings[patient][recording].columns)\n",
    "\n",
    "parameter_present_in_any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which ventilator settings are present in all recordings\n",
    "parameter_present_in_all = parameter_present_in_any.copy()\n",
    "for patient in vent_settings:\n",
    "    for recording in vent_settings[patient]:\n",
    "        parameter_present_in_all &= set(vent_settings[patient][recording].columns)\n",
    "\n",
    "parameter_present_in_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some recordings Timax has been set although there was no PSV mode used. Please clarify this.\n",
    "\n",
    "In some recordings PIP has been also set suggesting that at least part of the recording was with VG off. This info will be inserted in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check which ventilator settings are present extra in  each recording\n",
    "for patient in vent_settings:\n",
    "    for recording in vent_settings[patient]:\n",
    "        extra_pars = set(vent_settings[patient][recording].columns) - parameter_present_in_all\n",
    "        if extra_pars:\n",
    "            print(patient, recording, extra_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vent_modes['LVD006']['2021-11-30_142736.417'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_settings['LVD006']['2021-11-30_142736.417'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vent_modes['LVD008']['2021-12-04_132746.283'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vent_settings['LVD008']['2021-12-04_132746.283'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is an example when the recording has both VG and noVG\n",
    "vent_settings['LVD002']['2021-11-08_105631.989'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if there are duplicated columns:\n",
    "for patient in vent_settings:\n",
    "    for recording in vent_settings[patient]:\n",
    "        if vent_settings[patient][recording].columns.duplicated().any():\n",
    "                print(f'Some columns are duplicated for {patient} {recording}')\n",
    "        else:\n",
    "            print(f'No duplicated columns for {patient} {recording}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Identify which recordings had only SIMV with or without VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "has_cmv = defaultdict(int); has_sippv = defaultdict(int); has_simv = defaultdict(int); \n",
    "has_psv = defaultdict(int); has_mmv = defaultdict(int); has_hfov = defaultdict(int); \n",
    "has_vg = defaultdict(int); has_novg = defaultdict(int)\n",
    "\n",
    "for patient in patients:\n",
    "    for recording in vent_modes[patient]:\n",
    "        try:\n",
    "            entries = [value.strip(' ') for value in vent_modes[patient][recording]['Text'].values]\n",
    "        \n",
    "            if 'Mode PC-CMV' in entries:\n",
    "                has_cmv[patient, recording] = 1\n",
    "        \n",
    "            if 'Mode PC-AC' in entries:\n",
    "                has_sippv[patient, recording] = 1\n",
    "\n",
    "            if 'Mode PC-SIMV' in entries:\n",
    "                has_simv[patient, recording] = 1\n",
    "        \n",
    "            if 'Mode PC-PSV' in entries:\n",
    "                has_psv[patient, recording] = 1\n",
    "       \n",
    "            if 'Mode PC-MMV' in entries:\n",
    "                has_mmv[patient, recording] = 1\n",
    "       \n",
    "            if 'Mode PC-HFO' in entries:\n",
    "                has_hfov[patient, recording] = 1\n",
    "       \n",
    "            if '/VG' in entries:\n",
    "                has_vg[patient, recording] = 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Some recordings have no slow_Text files but mode was always SIMV\n",
    "            print(f'No data stored for {patient}, {recording}', e)\n",
    "            has_simv[patient, recording] = 1\n",
    "            continue\n",
    "            \n",
    "        # This is to identify recordings when VG was off during (or during part of) the recording\n",
    "        if 'PIP_set [mbar]' in vent_settings[patient][recording].columns:\n",
    "            has_novg[patient, recording] = 1  \n",
    "            \n",
    "    \n",
    "has_vent_mode = DataFrame([has_cmv, has_sippv, has_simv, has_psv, has_mmv, has_hfov, has_vg, has_novg]).T\n",
    "has_vent_mode.columns = ['cmv', 'sippv', 'simv', 'psv', 'mmv', 'hfov', 'vg', 'novg']\n",
    "has_vent_mode.fillna(0, inplace = True)\n",
    "has_vent_mode.sort_index(inplace = True)\n",
    "\n",
    "has_vent_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the DataFrame with the ventilation modes as an excel files and the individual modes as text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in ['sippv', 'simv', 'psv', 'mmv', 'hfov', 'vg', 'novg']:\n",
    "    fhandle = open(os.path.join(DIR_WRITE, f'recording_list_{mode}.txt'), 'w')\n",
    "    for recording in sorted(has_vent_mode[has_vent_mode[mode] == 1].index):\n",
    "        fhandle.write( '%s ' % recording[0])\n",
    "    fhandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of recording parts\n",
    "len(has_vent_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of patients\n",
    "len(sorted(set(patient for patient, recording in has_vent_mode.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "has_vent_mode.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_vent_mode.to_excel(os.path.join(DIR_WRITE, 'vent_modes_all_draeger_all.xlsx'), sheet_name='vent_modes_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider only SIMV with or without VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_simv_frme = has_vent_mode[has_vent_mode['simv'] == 1]\n",
    "len(has_simv_frme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_simv_frme.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simv_only_frme = has_vent_mode[(has_vent_mode['simv'] == 1) & \n",
    "    (has_vent_mode[['cmv', 'sippv', 'simv', 'psv', 'mmv', 'hfov']].sum(axis=1) == 1)]\n",
    "len(simv_only_frme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "simv_only_frme.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_other_mode = set(has_simv_frme.index) -  set(simv_only_frme.index)\n",
    "has_other_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export vent mode frame as csv file and as pickle dump\n",
    "\n",
    "has_simv_frme.to_csv(os.path.join(DIR_WRITE, 'has_simv_frme.csv'))\n",
    "\n",
    "with open(os.path.join(DATA_DUMP, 'has_simv_frme.pickle'), 'wb') as handle:\n",
    "    pickle.dump(has_simv_frme, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patients who only received conventional ventilation\n",
    "recordings_has_simv = list(has_simv_frme.index)\n",
    "len(recordings_has_simv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_has_simv[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patients who only received conventional ventilation\n",
    "patients_has_simv = sorted(set(patient for patient, recording in recordings_has_simv))\n",
    "len(patients_has_simv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Limit clinical details to the selected recordings (only conventional modes with or without VG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details_recordings = \\\n",
    "    clinical_details_recordings[clinical_details_recordings['Patient'].isin(patients_has_simv)]\n",
    "clinical_details_patients = \\\n",
    "    clinical_details_patients[clinical_details_patients['Patient'].isin(patients_has_simv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clinical_details_recordings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clinical_details_patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clinical_details_recordings), len(clinical_details_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clinical data\n",
    "\n",
    "clinical_details_recordings.to_csv(os.path.join(DIR_WRITE, 'clinical_details_recordings_simv.csv'))\n",
    "clinical_details_patients.to_csv(os.path.join(DIR_WRITE, 'clinical_details_patients_simv.csv'))\n",
    "\n",
    "with open(os.path.join(DATA_DUMP, 'clinical_details_recordings_simv.pickle'), 'wb') as handle:\n",
    "    pickle.dump(clinical_details_recordings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.path.join(DATA_DUMP, 'clinical_details_patients_simv.pickle'), 'wb') as handle:\n",
    "    pickle.dump(clinical_details_patients, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Import ventilator parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_selector(col):\n",
    "    # There are sometimes extra columns in the imported DataFrames with no header. Exclude them.\n",
    "    return '5001' in col or '8272' in col or col in ['Time [ms]', 'Date', 'Time', 'Rel.Time [s]',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_remover(col_name):\n",
    "    if '|' in col_name:\n",
    "        return col_name.split('|')[1]\n",
    "    else:\n",
    "        return col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_filter(dframe):\n",
    "    to_choose_from = \\\n",
    "        ['MV [L/min]', 'MVi [L/min]', 'MVe [L/min]',  'MVemand [L/min]', 'MVespon [L/min]', 'MVleak [L/min]',\n",
    "         'VT [mL]', 'VTmand [mL]', 'VTspon [mL]', 'VTimand [mL]', 'VTispon [mL]', 'VTemand [mL]', 'VTespon [mL]',   \n",
    "         'PIP [mbar]', 'Pmean [mbar]', 'PEEP [mbar]', \n",
    "         'RR [1/min]', 'RRmand [1/min]', 'RRspon [1/min]', 'RRtrig [1/min]',\n",
    "         'Tispon [s]', '% leak [%]', '% MVspon [%]', 'FiO2 [%]',]\n",
    "    \n",
    "    # Columns are not always present\n",
    "    col_to_keep = sorted(set(dframe.columns) & set(to_choose_from))\n",
    "    return(dframe[col_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_2(patient, recording, nrows = None):\n",
    "  \n",
    "    path = os.path.join(DIR_READ_VENT, patient, f'CsvLogBase_{recording}_slow_Measurement.csv')\n",
    "    # This escaping characters with encoding errors with blackslashes \n",
    "    # that pd.csv can subsequently handle\n",
    "    with open(path, encoding='utf8' , errors = 'backslashreplace',) as input_fd:\n",
    "        dframe = pd.read_csv(input_fd, keep_date_col = 'True', usecols = column_selector, nrows = nrows,\n",
    "        parse_dates = [['Date', 'Time']])\n",
    "        \n",
    "    dframe.index = dframe['Date_Time']\n",
    "    dframe = dframe.rename(tag_remover, axis = 1)\n",
    "    dframe = column_filter(dframe)\n",
    "    # Resampling to remove half-empty rows\n",
    "    # This resampling works because the 'mean()' methods ignores na values as a default\n",
    "    return dframe.resample('1S').mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "slow_measurements = defaultdict(dict)\n",
    "for patient, recording in recordings_has_simv:\n",
    "    print(datetime.now(), ' ', f'Working on {patient} - {recording}')\n",
    "    slow_measurements[patient][recording] = process_files_2(patient, recording)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Combine ventilator parameters and ventilator settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "combined = defaultdict(dict)\n",
    "for patient, recording in recordings_has_simv:\n",
    "    #print(patient, recording)\n",
    "    settings = vent_settings[patient][recording].reindex(slow_measurements[patient][recording].index, \n",
    "        method = 'ffill').copy()\n",
    "    combined[patient][recording] = pd.merge(slow_measurements[patient][recording], settings,\n",
    "        how = 'outer', left_index= True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Correct relevant parameters to body weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details_recordings = clinical_details_recordings.set_index(['Patient', 'Recording'], drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details_recordings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_correct(patient, recording, dframe):\n",
    "    \n",
    "    to_weight_correct_potential = {'MV [L/min]', 'MVe [L/min]',\n",
    "       'MVemand [L/min]', 'MVespon [L/min]', 'MVi [L/min]', 'MVleak [L/min]',\n",
    "       'VTemand [mL]', 'VTespon [mL]', 'VTimand [mL]', 'VTispon [mL]', 'VTmand [mL]', 'VT [mL]',\n",
    "       'VTspon [mL]', 'VT_set [mL]'}\n",
    "    \n",
    "    # Not all columns are always present\n",
    "    to_weight_correct_actual = to_weight_correct_potential & set(dframe.columns)\n",
    "    \n",
    "    wt = clinical_details_recordings.loc[patient, recording]['Current weight']\n",
    "   \n",
    "    for par in to_weight_correct_actual:\n",
    "        par_new = par[:-1] + '/kg' + par[-1]\n",
    "        dframe[par_new] = dframe[par] / wt * 1000\n",
    "        del dframe[par]\n",
    "        \n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for patient, recording in recordings_has_simv:\n",
    "    print(patient, recording)\n",
    "    combined[patient][recording] = weight_correct(patient, recording, combined[patient][recording])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Add Pinfl, VTdiff, Pdiff, RRdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD001']['2021-09-27_204445.625'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for patient, recording in recordings_has_simv:\n",
    "    #print(patient, recording)\n",
    "    \n",
    "    if len({'PIP [mbar]', 'PEEP_set [mbar]'} & set(combined[patient][recording].columns)) == 2:\n",
    "        combined[patient][recording]['Pinfl_mand [mbar]'] = combined[patient][recording]['PIP [mbar]'] - \\\n",
    "        combined[patient][recording]['PEEP_set [mbar]']\n",
    "        \n",
    "    if len({'PS_set [mbar]', 'PEEP_set [mbar]'} & set(combined[patient][recording].columns)) == 2:\n",
    "        combined[patient][recording]['PIP_spon [mbar]'] = combined[patient][recording]['PS_set [mbar]'] + \\\n",
    "        combined[patient][recording]['PEEP_set [mbar]']\n",
    "    \n",
    "    if len({'PIP [mbar]', 'Pmax_set [mbar]'} & set(combined[patient][recording].columns)) == 2:\n",
    "        combined[patient][recording]['Pdiff [mbar]'] = combined[patient][recording]['Pmax_set [mbar]'] - \\\n",
    "        combined[patient][recording]['PIP [mbar]']\n",
    "            \n",
    "    # In some recordings there is only VT rather than VTmand. However, prefer VTmand\n",
    "    if len({'VT [mL/kg]', 'VT_set [mL/kg]'} & set(combined[patient][recording].columns)) == 2:\n",
    "        combined[patient][recording]['VTdiff [mL/kg]'] = combined[patient][recording]['VT [mL/kg]'] - \\\n",
    "        combined[patient][recording]['VT_set [mL/kg]']\n",
    "    \n",
    "    if len({'VTmand [mL/kg]', 'VT_set [mL/kg]'} & set(combined[patient][recording].columns)) == 2:\n",
    "        combined[patient][recording]['VTdiff [mL/kg]'] = combined[patient][recording]['VTmand [mL/kg]'] - \\\n",
    "        combined[patient][recording]['VT_set [mL/kg]']\n",
    "    \n",
    "    if len({'RRmand [1/min]', 'RR_set [1/min]'} & set(combined[patient][recording].columns)) == 2:\n",
    "        combined[patient][recording]['RRdiff [1/min]'] = \\\n",
    "        combined[patient][recording]['RRmand [1/min]'] - combined[patient][recording]['RR_set [1/min]']\n",
    "        \n",
    "    # sort columns\n",
    "    combined[patient][recording].sort_index(axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Add info about leak compensation\n",
    "\n",
    "This information is not included directly in the downloaded data. However, when leak compensation is off, the VTmand is essentially (within 0.001 mL/kg) identical to VTemand. When leak compensation is on, VTmand > VTemand because there is always some, even if minimal, leak\n",
    "\n",
    "In the recordings where VTmand is not available use VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient, recording in recordings_has_simv:\n",
    "    if 'VTmand [mL/kg]' in combined[patient][recording].columns and \\\n",
    "        'VTemand [mL/kg]' in combined[patient][recording].columns:\n",
    "        print(patient, recording, 'VTmand-VTemand = ', (combined[patient][recording]['VTmand [mL/kg]'] - \n",
    "            combined[patient][recording]['VTemand [mL/kg]']).mean())\n",
    "        \n",
    "    elif 'VT [mL/kg]' in combined[patient][recording].columns and \\\n",
    "        'VTemand [mL/kg]' in combined[patient][recording].columns:\n",
    "        print(patient, recording, 'VT-VTemand = ', (combined[patient][recording]['VT [mL/kg]'] - \n",
    "            combined[patient][recording]['VTemand [mL/kg]']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient, recording in recordings_has_simv:\n",
    "    if 'VTmand [mL/kg]' in combined[patient][recording].columns and \\\n",
    "        'VTemand [mL/kg]' in combined[patient][recording].columns:\n",
    "        if (combined[patient][recording]['VTmand [mL/kg]'] - \n",
    "            combined[patient][recording]['VTemand [mL/kg]']).mean() < 0.001:\n",
    "            combined[patient][recording]['leak compensation'] = 'off'\n",
    "        else:\n",
    "            combined[patient][recording]['leak compensation'] = 'on'\n",
    "    \n",
    "    elif 'VT [mL/kg]' in combined[patient][recording].columns and \\\n",
    "         'VTemand [mL/kg]' in combined[patient][recording].columns:\n",
    "        if (combined[patient][recording]['VT [mL/kg]'] - \n",
    "            combined[patient][recording]['VTemand [mL/kg]']).mean() < 0.001:\n",
    "            combined[patient][recording]['leak compensation'] = 'off'\n",
    "        else:\n",
    "            combined[patient][recording]['leak compensation'] = 'on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the leak compensation categorical\n",
    "for patient, recording in recordings_has_simv:\n",
    "    combined[patient][recording]['leak compensation'] = \\\n",
    "        combined[patient][recording]['leak compensation'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[patient][recording].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. For those recordings which have other modes, keep only SIMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_other_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD002']['2021-11-08_105631.989'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD002']['2021-11-08_105631.989'] = \\\n",
    "    combined['LVD002']['2021-11-08_105631.989'].loc[:'2021-11-09 13:10:24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD004']['2021-10-25_211444.182'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD004']['2021-10-25_211444.182'] = \\\n",
    "    combined['LVD004']['2021-10-25_211444.182'].loc[:'2021-10-26 11:37:15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD005']['2021-12-16_092336.151'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD005']['2021-12-16_092336.151'] = \\\n",
    "    combined['LVD005']['2021-12-16_092336.151'].loc[:'2021-12-20 22:40:08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD005']['2021-12-22_203909.404'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD005']['2021-12-22_203909.404'] = \\\n",
    "    combined['LVD005']['2021-12-22_203909.404'].loc[:'2021-12-26 12:20:20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD005']['2021-12-28_154455.897'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD005']['2021-12-28_154455.897'] = \\\n",
    "    combined['LVD005']['2021-12-28_154455.897'].loc[:'2021-12-31 14:13:09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD008']['2021-12-04_132746.283'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD008']['2021-12-04_132746.283'] = \\\n",
    "    combined['LVD008']['2021-12-04_132746.283'].loc['2021-12-04 15:24:14':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD008']['2021-12-06_102618.106'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD008']['2021-12-04_132746.283'] = \\\n",
    "    combined['LVD008']['2021-12-04_132746.283'].loc[:'2021-12-07 16:57:35']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD009']['2021-12-09_123914.130'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD009']['2021-12-09_123914.130'] = \\\n",
    "    combined['LVD009']['2021-12-09_123914.130'].loc[:'2021-12-11 20:07:32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD010']['2021-12-09_122846.010'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD010']['2021-12-09_122846.010'] = \\\n",
    "    combined['LVD010']['2021-12-09_122846.010'].loc[:'2021-12-10 08:06:45']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vent_modes['LVD013']['2022-01-07_151845.678'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD013']['2022-01-07_151845.678'] = \\\n",
    "    combined['LVD013']['2022-01-07_151845.678'].loc[:'2022-01-11 08:46:13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vent_modes['LVD013']['2022-02-11_095849.673'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD013']['2022-02-11_095849.673'] = \\\n",
    "    combined['LVD013']['2022-02-11_095849.673'].loc[:'2022-02-12 22:14:54']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD015']['2022-01-22_194526.833'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD015']['2022-01-22_194526.833'] = \\\n",
    "    combined['LVD015']['2022-01-22_194526.833'].loc[:'2022-01-23 19:52:13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes['LVD016']['2022-01-21_113956.352'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LVD016']['2022-01-21_113956.352'] = \\\n",
    "    combined['LVD016']['2022-01-21_113956.352'].loc['2022-01-21 11:45:04':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Export data\n",
    "\n",
    "#### Ventilator parameters and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for patient in sorted(combined.keys()):\n",
    "    for recording in combined[patient]:\n",
    "        print(f'Exporting {patient}  {recording}')\n",
    "        combined[patient][recording].to_hdf(os.path.join(DATA_DUMP, f'{patient}_{recording}_pars_and_settings.h5'),\n",
    "        format = 'table', key = patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
